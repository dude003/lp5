{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgEj_6lzyM-u",
        "outputId": "dc91c215-26fc-477b-b64b-6db8fe42e0ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void addVectors(int* A, int* B, int* C, int n) //__global__: Specifies that this function is a CUDA kernel, meaning it runs on the GPU and is called from the CPU.\n",
        "{\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x; // blockIdx.x: The index of the block within the grid. blockDim.x: The number of threads in each block. threadIdx.x: The index of the thread within the block.\n",
        "    if (i < n) // Ensures that threads do not access memory beyond the allocated array.\n",
        "    {\n",
        "        C[i] = A[i] + B[i]; // Adds corresponding elements from vectors A and B, storing the result in C.\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int n = 1000000; // The size of the vectors (one million elements).\n",
        "    int* A, * B, * C; // Pointers for the host (CPU) memory.\n",
        "    int size = n * sizeof(int); // The memory size required for each vector in bytes.\n",
        "\n",
        "    // Allocate memory on the host\n",
        "    cudaMallocHost(&A, size); //  Allocates pinned (page-locked) memory on the host. This improves the speed of memory transfer between host and device.\n",
        "    cudaMallocHost(&B, size);\n",
        "    cudaMallocHost(&C, size);\n",
        "\n",
        "    // Initialize the vectors\n",
        "    for (int i = 0; i < n; i++)\n",
        "    {\n",
        "        A[i] = i; // Fills A with values [0, 1, 2, ..., n-1].\n",
        "        B[i] = i * 2;  // Fills B with values [0, 2, 4, ..., 2*(n-1)].\n",
        "    }\n",
        "    // Allocate memory on the device\n",
        "    int* dev_A, * dev_B, * dev_C;\n",
        "    cudaMalloc(&dev_A, size); // cudaMalloc(&dev_A, size): Allocates size bytes of GPU memory for A.\n",
        "    cudaMalloc(&dev_B, size); // cudaMalloc(&dev_B, size): Allocates size bytes of GPU memory for B.\n",
        "    cudaMalloc(&dev_C, size); // cudaMalloc(&dev_C, size): Allocates size bytes of GPU memory for C.\n",
        "\n",
        "    // Copy data from host to device\n",
        "    cudaMemcpy(dev_A, A, size, cudaMemcpyHostToDevice); // cudaMemcpy(dest, src, size, cudaMemcpyHostToDevice): Copies data from host memory to device memory.\n",
        "    cudaMemcpy(dev_B, B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch the kernel\n",
        "    int blockSize = 256; // Defines 256 threads per block.\n",
        "    int numBlocks = (n + blockSize - 1) / blockSize; // Ensures that all elements are covered\n",
        "    addVectors<<< numBlocks, blockSize >>>(dev_A, dev_B, dev_C, n); // This launches the kernel with numBlocks blocks and blockSize threads per block. Each thread computes C[i] = A[i] + B[i] in parallel.\n",
        "\n",
        "    // Copy data from device to host\n",
        "    cudaMemcpy(C, dev_C, size, cudaMemcpyDeviceToHost); // Copies the computed results from device memory (dev_C) to host memory (C).\n",
        "\n",
        "    // Print the results\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        cout << C[i] << \" \"; // Prints the first 10 elements of C to verify the computation.\n",
        "    }\n",
        "    cout << endl;\n",
        "\n",
        "    // Free memory\n",
        "    cudaFree(dev_A); // releases memory on the GPU.\n",
        "    cudaFree(dev_B);\n",
        "    cudaFree(dev_C);\n",
        "    cudaFreeHost(A); //  releases pinned memory on the CPU.\n",
        "    cudaFreeHost(B);\n",
        "    cudaFreeHost(C);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2yaYmUsybv5",
        "outputId": "c7527081-2e26-4831-f2f1-ddff01474461"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!nvcc vector_add.cu -o vector_add\n",
        "!rm -rf /usr/local/cuda           # Removes any previous CUDA installations (only needed in certain environments).\n",
        "!ln -s  /usr/local/cuda-12.5 /usr/local/cuda        # Links to CUDA 12.2.\n",
        "!nvcc -arch=sm_75 add.cu -o add         # Compiles the CUDA program (nvcc is the CUDA compiler)."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye7J8dBezP_6",
        "outputId": "1a924a3b-8c77-43fc-f2ee-5cf5f5219bbb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01madd.cu(46)\u001b[0m: \u001b[01;31merror\u001b[0m: expected an expression\n",
            "      addVectors<<>>(dev_A, dev_B, dev_C, n);\n",
            "                  ^\n",
            "\n",
            "1 error detected in the compilation of \"add.cu\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwTvfeP1zfev",
        "outputId": "24fdec57-294d-4d81-8395-20c5dd55dd09"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0 0 0 0 0 0 0 0 0 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBN66EsGzouF",
        "outputId": "adce3544-5ad4-4ab7-95d6-99f03f4efc91"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: ./add: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mul.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void matmul(int* A, int* B, int* C, int N) {\n",
        "    int Row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int Col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (Row < N && Col < N) {\n",
        "        int Pvalue = 0;\n",
        "        for (int k = 0; k < N; k++) {\n",
        "            Pvalue += A[Row * N + k] * B[k * N + Col];\n",
        "        }\n",
        "        C[Row * N + Col] = Pvalue;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 512;\n",
        "    int size = N * N * sizeof(int);\n",
        "    int *A, *B, *C;\n",
        "    int *dev_A, *dev_B, *dev_C;\n",
        "\n",
        "    // Allocate pinned memory on host for better performance\n",
        "    cudaMallocHost((void**)&A, size);\n",
        "    cudaMallocHost((void**)&B, size);\n",
        "    cudaMallocHost((void**)&C, size);\n",
        "\n",
        "    // Allocate memory on device\n",
        "    cudaMalloc((void**)&dev_A, size);\n",
        "    cudaMalloc((void**)&dev_B, size);\n",
        "    cudaMalloc((void**)&dev_C, size);\n",
        "\n",
        "    // Initialize matrices A and B\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            A[i * N + j] = i * N + j;\n",
        "            B[i * N + j] = j * N + i;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Copy matrices to device\n",
        "    cudaMemcpy(dev_A, A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_B, B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define block and grid size\n",
        "    dim3 dimBlock(16, 16);\n",
        "    dim3 dimGrid((N + dimBlock.x - 1) / dimBlock.x, (N + dimBlock.y - 1) / dimBlock.y);\n",
        "\n",
        "    // Launch kernel\n",
        "    matmul<<>>(dev_A, dev_B, dev_C, N);\n",
        "\n",
        "    // Copy result back to host\n",
        "    cudaMemcpy(C, dev_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print a portion of the result matrix\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        for (int j = 0; j < 10; j++) {\n",
        "            std::cout << C[i * N + j] << \" \";\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "\n",
        "    // Free memory\n",
        "    cudaFree(dev_A);\n",
        "    cudaFree(dev_B);\n",
        "    cudaFree(dev_C);\n",
        "    cudaFreeHost(A);\n",
        "    cudaFreeHost(B);\n",
        "    cudaFreeHost(C);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccSKvxQC3e95",
        "outputId": "fe5889d6-66ff-4d29-ef19-15bec3683e9e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mul.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /usr/local/cuda           # Removes any previous CUDA installations (only needed in certain environments).\n",
        "!ln -s  /usr/local/cuda-12.5 /usr/local/cuda        # Links to CUDA 12.2.\n",
        "!nvcc -arch=sm_75 mul.cu -o mul         #"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlgjIon548TH",
        "outputId": "6a6b02a7-a93d-48e1-ed02-5de0e0d25527"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mmul.cu(51)\u001b[0m: \u001b[01;31merror\u001b[0m: expected an expression\n",
            "      matmul<<>>(dev_A, dev_B, dev_C, N);\n",
            "              ^\n",
            "\n",
            "1 error detected in the compilation of \"mul.cu\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./mul\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_-96KEi4_fU",
        "outputId": "6b7e6a23-6654-4979-a2d4-915fec6eb8ad"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: ./mul: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UFTgbjam5Dtm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}